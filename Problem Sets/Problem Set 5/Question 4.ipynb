{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> DATA 319: Model-based and Data-based Methods for Data Analytics. Summer 2024 </h2>\n",
    "<h3> Problem Set 5 </h3>\n",
    "<h3> Team <i> (Insert your team number here) </i></h3>\n",
    "<h3> Type students' names <i> (only those who contributed to the group work)</i> here</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. In your own words provide short responses to the following questions:\n",
    "\n",
    "##### (a) Why is it useful to normalize or standardize the data before performing PCA?\n",
    "\n",
    "##### (b) Describe one method for determining how to select the number of principal components when performing PCA.\n",
    "\n",
    "##### (c) Give an example of a dataset where you expect that MDS would return more useful results than PCA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Suppose that a data set consists of two variables $X = (X_1, X_2)$ with covariance matrix \n",
    "\n",
    "$$\\Sigma = \\begin{bmatrix}1&0.75\\\\0.75&1\\end{bmatrix}$$\n",
    "\n",
    "##### (a) What are the eigenvalues and eigenvectors of $\\Sigma$?\n",
    "\n",
    "##### (b) If $Y_1$ and $Y_2$ are the principal components of $X$, then what are $\\text{Var}(Y_1)$, $\\text{Var}(Y_2)$, $\\text{Cov}(Y_1, Y_2)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. This problem references the `education_income.csv` dataset, which includes different education and income features as well as population characteristics and party vote in 2020 election for 50 U.S. States.\n",
    "\n",
    "##### (a) Use Python to study the principal components of this dataset. Create a visualization that displays the proportion of variance explained and the cumulative proportion of variance of scaled data explained by each principal component.\n",
    "\n",
    "##### (b) How many principal components are needed to explain at least 90% of the variance in the scaled data?\n",
    "\n",
    "##### (c) Compute the covariance matrix of the full set of principal components.\n",
    "\n",
    "##### (d) Provide a scatterplot of the first two principal components, colored by the 2020 party vote.\n",
    "\n",
    "##### (e) Compute the correlations between the original variables (from scaled data) and the first two principal components. \n",
    "\n",
    "##### (f) Compute the loadings of the original variables (from scaled data) in the first two principal components. \n",
    "\n",
    "##### (g) Use the obtained correlation coefficients from (e) and loadings from (f) to provide a brief interpretation of the principal components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Consider three impurity measures for decision trees we learned in class. Feel free to refer to [Chapter 12 of MMDS textbook](http://infolab.stanford.edu/~ullman/mmds/ch12n.pdf) (paragraph 12.5. Decision Trees).\n",
    "\n",
    "##### (a) Suppose a training set has examples in four classes, and the fractions of examples in these classes are 1/2, 1/3, 1/8, and 1/24. What is the impurity of the root of a decision tree designed for this training set under each of these three impurity measures?\n",
    "\n",
    "Accuracy:  0.5\n",
    "Gini Impurity:  0.6215277777777778\n",
    "Entropy:  1.5943609377704338\n",
    "\n",
    "See Code Block Below For Work\n",
    "\n",
    "##### (b) If a dataset consists of examples belonging to n different classes, what are the possible maximum and minimum values for each of these three impurity measures? \n",
    "\n",
    "1. For Accuracy, the Minimum Value would be 0 when every prediction was incorrect. The maximum is 1 or 100% for when every prediction matches reality.\n",
    "\n",
    "1. For GINI Impurity, the minimum is 0 which means that all examples belong to the same class. The maximum value would be if the dataset was spread evenly across all of the classes which would have a value of 1 - 1/n\n",
    "\n",
    "1. For Entropy, the minimum is 0 like GINI impurity because all of the examples belong to a single class and there is no disorder. The maximum is log_2(n) when the classes are evenly distributed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5\n",
      "Gini Impurity:  0.6215277777777778\n",
      "Entropy:  1.5943609377704338\n"
     ]
    }
   ],
   "source": [
    "#4A Calculate Impurity\n",
    "import math\n",
    "\n",
    "#Accuracy\n",
    "accuracy = max(1/2, 1/3, 1/8, 1/24)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "#GINI Impurity\n",
    "gini = 1 - ((1/2)**2 + (1/3)**2 + (1/8)**2 + (1/24)**2)\n",
    "print(\"Gini Impurity: \", gini)\n",
    "\n",
    "#Entropy\n",
    "entropy = -1 * ((1/2)*math.log2(1/2) + (1/3)*math.log2(1/3) + (1/8)*math.log2(1/8) + (1/24)*math.log2(1/24))\n",
    "print(\"Entropy: \", entropy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. This problem references the `cancer_data.csv` dataset, which includes various features of tumors that are classified either as \"Malignant\" or \"Benign\".\n",
    "\n",
    "##### (a) Begin by exploring the data graphically in order to investigate the association between diagnosis and the physical measurements. Which of these features seem most likely to be useful in predicting diagnosis? Choose three features to use for your learning methods below and briefly justify your choices.\n",
    "\n",
    "##### (b) Now perform PCA to this dataset to reduce the dimension of this dataset to 3 dimensions (i.e. extract 3 principal components). What is the ratio of the variance in the scaled data that is explained cumulatively by the first 3 principal components?\n",
    "\n",
    "##### (c) Use a k-nearest neighbors approach with three different values of k (k=3, k=5, k=10) to predict the diagnosis values of tumors. Conduct this exercise first using the three selected features in (a) and then using the three principal components from (b). For reproducibility purposes set the test set to be 20% of the dataset and set the random state to 42. Report the error for each choice of k in both exercises. Does the error always improve as k grows?\n",
    "\n",
    "##### (d) Pick one additional supervised learning method we learned in class (or beyond) to apply both to the three selected features in (a) and to the three principal components from (b). Compare your results to the results from part(c). Which method performs better?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
